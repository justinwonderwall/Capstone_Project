{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac8bd993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load data\n",
    "df = pd.read_csv('../data/processed/merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bbe7aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['course_id', 'course_type_broad', 'unit_id', 'unit_level_code',\n",
       "       'unit_level_name', 'unit_foe_detailed', 'unit_foe_narrow', 'foe_code',\n",
       "       'unit_foe_broad', 'eftsl_2024', 'funding_nation', 'funding_type',\n",
       "       'overload', 'funding_cluster', 'max_student_contrib_2024',\n",
       "       'commonwealth_contrib_2024', 'max_student_contrib_gf_2024',\n",
       "       'commonwealth_contrib_gf_2024', 'is_funding_cluster_variable',\n",
       "       'special_course_code', 'max_contrib_indicator', 'foe_detailed_title',\n",
       "       'foe_detailed', 'foe_narrow', 'foe_broad', 'foe_error', 'special_code',\n",
       "       'CSP_gov_payment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665dc54",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b28883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features for modeling\n",
    "features_to_use = [\n",
    "    'course_id', 'course_type_broad', 'unit_id', 'unit_level_code',\n",
    "       'unit_level_name', 'unit_foe_detailed', 'unit_foe_narrow', 'foe_code',\n",
    "       'unit_foe_broad', 'eftsl_2024', 'funding_nation', 'funding_type',\n",
    "       'overload', 'funding_cluster', 'max_student_contrib_2024',\n",
    "       'commonwealth_contrib_2024', 'max_student_contrib_gf_2024',\n",
    "       'commonwealth_contrib_gf_2024', 'is_funding_cluster_variable',\n",
    "       'special_course_code', 'max_contrib_indicator', 'foe_detailed_title',\n",
    "       'foe_detailed','special_code',\n",
    "]\n",
    "categorical_features = ['sex_ed', 'ethnicity', 'mode_of_arrival', 'primary_diagnosis_ICD10AM_chapter', 'arrival_day_of_week']\n",
    "numerical_features = ['age_ed', 'triage_category', 'mental_health_attendance', 'arrival_hour', 'is_weekend']\n",
    "\n",
    "# Create a preprocessing pipeline for one-hot encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough' # Keep numerical features as they are\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d41aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define final features and target\n",
    "X = merged_df[features_to_use]\n",
    "y = merged_df['was_admitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43cfdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Corrected Data Splitting (70% Train, 15% Validation, 15% Test) ---\n",
      "Training set size: 363572\n",
      "Validation set size: 77908\n",
      "Test set size: 77909\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Corrected Data Splitting (70% Train, 15% Validation, 15% Test) ---\")\n",
    "# First split: 70% train, 30% temp (val + test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Second split: Split the 30% temp set into 50% validation and 50% test (which is 15% of the original data each)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a49515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Handling Class Imbalance ---\n",
      "Calculated scale_pos_weight for XGBoost: 4.26\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n---Handling Class Imbalance ---\")\n",
    "counts = y_train.value_counts()\n",
    "scale_pos_weight_value = counts[0] / counts[1]\n",
    "print(f\"Calculated scale_pos_weight for XGBoost: {scale_pos_weight_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper function for evaluation ---\n",
    "def evaluate_models(models, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"A helper function to train and evaluate a dictionary of models.\"\"\"\n",
    "    results_data = []\n",
    "    for name, model in models.items():\n",
    "        print(f\"  Training and evaluating {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        results_data.append([name, accuracy_score(y_test, y_pred), precision_score(y_test, y_pred), \n",
    "                               recall_score(y_test, y_pred), f1_score(y_test, y_pred), auc])\n",
    "    \n",
    "    return pd.DataFrame(results_data, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC']).sort_values('ROC AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f86f76",
   "metadata": {},
   "source": [
    "#### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683bca67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating 3 models using ALL features ---\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "print(\"\\n--- Evaluating 3 models using ALL features ---\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define the 3 models\n",
    "lr = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000))])\n",
    "rf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))])\n",
    "xgb = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', xgb.XGBClassifier(random_state=42, scale_pos_weight=scale_pos_weight_value, eval_metric='logloss'))])\n",
    "\n",
    "models_features = {\n",
    "    \"Logistic Regression\": lr,\n",
    "    \"Random Forest\": rf,\n",
    "    \"XGBoost\": xgb\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47aad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training and evaluating Logistic Regression...\n",
      "  Training and evaluating Random Forest...\n",
      "  Training and evaluating XGBoost...\n",
      "\n",
      "--- Performance on train data with ALL features ---\n",
      "                 Model  Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
      "0  Logistic Regression  0.951251   0.815065  0.962089  0.882495  0.994975\n",
      "2              XGBoost  0.946065   0.785968  0.984687  0.874177  0.994967\n",
      "1        Random Forest  0.967603   0.947208  0.878710  0.911674  0.994868\n"
     ]
    }
   ],
   "source": [
    "results_all_features = evaluate_models(models_features, X_train, y_train, X_test, y_test)\n",
    "print(\"\\n--- Performance on train data with ALL features ---\")\n",
    "print(results_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de04c558",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385e424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---  Selecting best features using SHAP ---\n",
      "  Calculating SHAP values... (This may take a moment)\n",
      "  SHAP calculation complete.\n",
      "Selected 6 original features based on SHAP: ['age_ed', 'triage_category', 'mental_health_attendance', 'arrival_hour', 'ethnicity', 'is_weekend']\n",
      "Created new data splits with 6 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml/lib/python3.12/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print(\"\\n---  Selecting best features using SHAP ---\")\n",
    "\n",
    "lgbm = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', lgb.LGBMClassifier(random_state=42, scale_pos_weight=scale_pos_weight_value,verbose=-1))])\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# --- SHAP Value Calculation ---\n",
    "# 1. We need to get the actual classifier model from the pipeline\n",
    "lgbm_classifier = lgbm.named_steps['classifier']\n",
    "\n",
    "# 2. We need the preprocessed data that the classifier was trained on.\n",
    "# We will use the validation set (X_val) for calculating SHAP values.\n",
    "# This is a good practice as it's a representative sample and faster than using the full training set.\n",
    "preprocessor = lgbm.named_steps['preprocessor']\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "# The output is a sparse matrix, convert it to a dense numpy array for SHAP\n",
    "X_val_transformed_dense = X_val_transformed.toarray()\n",
    "# Get the feature names from the preprocessor\n",
    "feature_names_raw = preprocessor.get_feature_names_out()\n",
    "\n",
    "\n",
    "# 3. Create a SHAP explainer and calculate SHAP values\n",
    "print(\"  Calculating SHAP values... (This may take a moment)\")\n",
    "explainer = shap.TreeExplainer(lgbm_classifier)\n",
    "# shap_values is a list of two arrays for binary classification (one for each class)\n",
    "shap_values = explainer.shap_values(X_val_transformed_dense)\n",
    "\n",
    "# 4. Calculate global feature importance from SHAP values\n",
    "# We take the mean absolute SHAP value for each feature for the positive class (class 1)\n",
    "shap_importance = np.mean(np.abs(shap_values[1]), axis=0)\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names_raw, \n",
    "    'shap_importance': shap_importance\n",
    "}).sort_values('shap_importance', ascending=False)\n",
    "\n",
    "print(\"  SHAP calculation complete.\")\n",
    "\n",
    "# --- Feature Selection based on SHAP importance ---\n",
    "# Select features with a mean absolute SHAP value greater than a small threshold\n",
    "selected_features_raw = importance_df[importance_df['shap_importance'] > 0.01]['feature'].tolist()\n",
    "\n",
    "# Map these raw encoded feature names back to the original columns (same logic as before)\n",
    "selected_features = []\n",
    "for f in selected_features_raw:\n",
    "    if f.startswith('remainder__'):\n",
    "        selected_features.append(f.replace('remainder__', ''))\n",
    "    elif f.startswith('cat__'):\n",
    "        col = f.replace('cat__', '').split('_')[0]\n",
    "        selected_features.append(col)\n",
    "    else:\n",
    "        selected_features.append(f)\n",
    "\n",
    "# Remove duplicates\n",
    "selected_features = list(dict.fromkeys([f for f in selected_features if f in X_train.columns]))\n",
    "print(f\"Selected {len(selected_features)} original features based on SHAP: {selected_features}\")\n",
    "\n",
    "# Create new dataframes for train, validation, and test sets with only the selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_val_selected = X_val[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "print(f\"Created new data splits with {len(selected_features)} features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d24ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Identify which of the selected features are categorical for the new preprocessor\n",
    "selected_categorical = [f for f in selected_features if f in categorical_features]\n",
    "\n",
    "# Create a new preprocessor for the selected feature subset\n",
    "preprocessor_selected = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), selected_categorical)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define the 3 models\n",
    "lr_selected = Pipeline(steps=[('preprocessor', preprocessor_selected), ('classifier', LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000))])\n",
    "rf_selected = Pipeline(steps=[('preprocessor', preprocessor_selected), ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))])\n",
    "xgb_selected = Pipeline(steps=[('preprocessor', preprocessor_selected), ('classifier', xgb.XGBClassifier(random_state=42, scale_pos_weight=scale_pos_weight_value, eval_metric='logloss'))])\n",
    "\n",
    "models_selected_features = {\n",
    "    \"Logistic Regression\": lr_selected, \n",
    "    \"Random Forest\": rf_selected, \n",
    "    \"XGBoost\": xgb_selected\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7766907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training and evaluating Logistic Regression...\n",
      "  Training and evaluating Random Forest...\n",
      "  Training and evaluating XGBoost...\n",
      "\n",
      "--- Performance on train data with select features ---\n",
      "                 Model  Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
      "0  Logistic Regression  0.951251   0.814310  0.963505  0.882647  0.994978\n",
      "2              XGBoost  0.944641   0.778231  0.991635  0.872067  0.994807\n",
      "1        Random Forest  0.955114   0.842806  0.939288  0.888435  0.991810\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "results_select_features = evaluate_models(models_selected_features, X_train_selected, y_train, X_test_selected, y_test)\n",
    "print(\"\\n--- Performance on train data with select features ---\")\n",
    "print(results_select_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da475ee",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294b45bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Hyperparameter Tuning on Selected Features ---\n",
      "  Tuning Random Forest...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best RF Params: {'classifier__n_estimators': 100, 'classifier__min_samples_leaf': 1, 'classifier__max_depth': 5}\n",
      "\n",
      "  Tuning XGBoost...\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best XGBoost Params: {'classifier__n_estimators': 100, 'classifier__max_depth': 3, 'classifier__learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n---Hyperparameter Tuning on Selected Features ---\")\n",
    "\n",
    "\n",
    "# --- Tune Random Forest ---\n",
    "print(\"  Tuning Random Forest...\")\n",
    "rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor_selected), ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))])\n",
    "rf_param_dist = {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [5, 10, None], 'classifier__min_samples_leaf': [1, 2, 4]}\n",
    "rf_rand_search = RandomizedSearchCV(rf_pipeline, rf_param_dist, n_iter=5, cv=3, scoring='roc_auc', random_state=42, n_jobs=-1, verbose=1)\n",
    "rf_rand_search.fit(X_val_selected, y_val)\n",
    "rf_tuned_pipeline = rf_rand_search.best_estimator_\n",
    "print(f\"Best RF Params: {rf_rand_search.best_params_}\")\n",
    "\n",
    "\n",
    "# --- Tune XGBoost ---\n",
    "print(\"\\n  Tuning XGBoost...\")\n",
    "xgb_pipeline = Pipeline(steps=[('preprocessor', preprocessor_selected), ('classifier', xgb.XGBClassifier(random_state=42, scale_pos_weight=scale_pos_weight_value,  eval_metric='logloss'))])\n",
    "xgb_param_dist = {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [3, 5, 7], 'classifier__learning_rate': [0.01, 0.05, 0.1]}\n",
    "xgb_rand_search = RandomizedSearchCV(xgb_pipeline, xgb_param_dist, n_iter=5, cv=3, scoring='roc_auc', random_state=42, n_jobs=-1, verbose=1)\n",
    "xgb_rand_search.fit(X_val_selected, y_val)\n",
    "xgb_tuned_pipeline = xgb_rand_search.best_estimator_\n",
    "print(f\"Best XGBoost Params: {xgb_rand_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c4a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of the newly tuned models\n",
    "tuned_models = {\n",
    "    \"Random Forest (Tuned)\": rf_tuned_pipeline,\n",
    "    \"XGBoost (Tuned)\": xgb_tuned_pipeline\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9becbc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training and evaluating Random Forest (Tuned)...\n",
      "  Training and evaluating XGBoost (Tuned)...\n",
      "\n",
      "--- Performance of Tuned Models on Test Set ---\n",
      "                   Model  Accuracy  Precision  Recall  F1 Score   ROC AUC\n",
      "1        XGBoost (Tuned)  0.943306   0.770438     1.0  0.870336  0.994956\n",
      "0  Random Forest (Tuned)  0.943306   0.770438     1.0  0.870336  0.994933\n"
     ]
    }
   ],
   "source": [
    "results_tuned = evaluate_models(tuned_models, X_val_selected, y_val, X_test_selected, y_test)\n",
    "\n",
    "print(\"\\n--- Performance of Tuned Models on Test Set ---\")\n",
    "print(results_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e0c147",
   "metadata": {},
   "source": [
    "#### Model Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Model Selection ---\n",
      "\n",
      "--- Overall Performance Summary ---\n",
      "                   Model  Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
      "0    Logistic Regression  0.951251   0.815065  0.962089  0.882495  0.994975\n",
      "1                XGBoost  0.946065   0.785968  0.984687  0.874177  0.994967\n",
      "2          Random Forest  0.967603   0.947208  0.878710  0.911674  0.994868\n",
      "3    Logistic Regression  0.951251   0.814310  0.963505  0.882647  0.994978\n",
      "4                XGBoost  0.944641   0.778231  0.991635  0.872067  0.994807\n",
      "5          Random Forest  0.955114   0.842806  0.939288  0.888435  0.991810\n",
      "6        XGBoost (Tuned)  0.943306   0.770438  1.000000  0.870336  0.994956\n",
      "7  Random Forest (Tuned)  0.943306   0.770438  1.000000  0.870336  0.994933\n",
      "\n",
      "🏆 The best model is 'Logistic Regression', with an ROC AUC of 0.9950.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Final Model Selection ---\")\n",
    "# Concatenate results for a final comparison\n",
    "# This part of your code is correct.\n",
    "final_comparison = pd.concat([results_all_features, results_select_features, results_tuned]).reset_index(drop=True)\n",
    "print(\"\\n--- Overall Performance Summary ---\")\n",
    "print(final_comparison)\n",
    "\n",
    "best_model_details = final_comparison.sort_values('ROC AUC', ascending=False).iloc[0]\n",
    "best_model_name = best_model_details['Model']\n",
    "\n",
    "print(f\"\\n🏆 The best model is '{best_model_name}', with an ROC AUC of {best_model_details['ROC AUC']:.4f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
